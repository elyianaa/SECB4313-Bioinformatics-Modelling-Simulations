{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11egXIcUlhCqWrV8Ht06xHlV0bcO1aoLm",
      "authorship_tag": "ABX9TyOgNuXzpznEHIml9GuSsy/c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elyianaa/SECB4313-Bioinformatics-Modelling-Simulations/blob/main/Lab1%20Heart%20Disease%20NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Data"
      ],
      "metadata": {
        "id": "aX639mFJfYXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import all library needed\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,BatchNormalization, Dropout\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "#confusion matrix visualization\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "metadata": {
        "id": "QSQSpueqcKGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 1. Link notebook with google drive and access data from your personal Gdrive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "### 2.Set the data path for dataset and model location (ex: model_loc = \"/content/gdrive/My Drive/Dataset/\")\n",
        "dataset_dir = \"/content/gdrive/My Drive/SECBH/20232024 SEM 2/\"\n",
        "model_loc = \"/content/gdrive/My Drive/SECBH/20232024 SEM 2/\"\n",
        "\n",
        "print(os.listdir(dataset_dir))\n",
        "data = pd.read_csv(dataset_dir+'heart.csv')"
      ],
      "metadata": {
        "id": "zvkTdnCzde8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c52ec34a-9ed6-4f69-ae2c-fa6807817eaa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "['Lab1.ipynb', 'STB W3 Elyiana & Marnisha.gdoc', 'heart.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EDA"
      ],
      "metadata": {
        "id": "fnoBow97feo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "4dJWqpfNf3xK",
        "outputId": "e19d1b39-57f4-4264-8a1a-5a8ec4b960b3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
              "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
              "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
              "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
              "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
              "\n",
              "   ca  thal  target  \n",
              "0   0     1       1  \n",
              "1   0     2       1  \n",
              "2   0     2       1  \n",
              "3   0     2       1  \n",
              "4   0     2       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1ee26cf-b762-4308-ab7e-ed4d147bdade\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1ee26cf-b762-4308-ab7e-ed4d147bdade')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e1ee26cf-b762-4308-ab7e-ed4d147bdade button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e1ee26cf-b762-4308-ab7e-ed4d147bdade');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cec729d5-bd1c-41f1-92f4-8b90b17baf88\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cec729d5-bd1c-41f1-92f4-8b90b17baf88')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cec729d5-bd1c-41f1-92f4-8b90b17baf88 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 303,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 29,\n        \"max\": 77,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          46,\n          66,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trestbps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 94,\n        \"max\": 200,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          104,\n          123\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51,\n        \"min\": 126,\n        \"max\": 564,\n        \"num_unique_values\": 152,\n        \"samples\": [\n          277,\n          169\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fbs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"restecg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thalach\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22,\n        \"min\": 71,\n        \"max\": 202,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          159,\n          152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exang\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oldpeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1610750220686348,\n        \"min\": 0.0,\n        \"max\": 6.2,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          1.9,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slope\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9Czg9D5gVUS",
        "outputId": "d5e0f3a8-9883-4757-a489-e8f8d131b6ef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "303"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset Shape: \", data.shape)\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jPkz9q0hB-l",
        "outputId": "e67c3e27-b0a1-44ca-e950-5d18b2be0dae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape:  (303, 14)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 303 entries, 0 to 302\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       303 non-null    int64  \n",
            " 1   sex       303 non-null    int64  \n",
            " 2   cp        303 non-null    int64  \n",
            " 3   trestbps  303 non-null    int64  \n",
            " 4   chol      303 non-null    int64  \n",
            " 5   fbs       303 non-null    int64  \n",
            " 6   restecg   303 non-null    int64  \n",
            " 7   thalach   303 non-null    int64  \n",
            " 8   exang     303 non-null    int64  \n",
            " 9   oldpeak   303 non-null    float64\n",
            " 10  slope     303 non-null    int64  \n",
            " 11  ca        303 non-null    int64  \n",
            " 12  thal      303 non-null    int64  \n",
            " 13  target    303 non-null    int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 33.3 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check missing values\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsB0rx71j4NN",
        "outputId": "d241655e-bc58-42d4-cbb6-82a6479c061e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age         0\n",
              "sex         0\n",
              "cp          0\n",
              "trestbps    0\n",
              "chol        0\n",
              "fbs         0\n",
              "restecg     0\n",
              "thalach     0\n",
              "exang       0\n",
              "oldpeak     0\n",
              "slope       0\n",
              "ca          0\n",
              "thal        0\n",
              "target      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking duplicated values\n",
        "data.duplicated().any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibpiSlH5kOH8",
        "outputId": "ca373031-4a98-4466-dffc-d261f10d0427"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "ssNzqe7TkWLK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.duplicated().any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd4LR4B_kh6Y",
        "outputId": "18eb5ee9-5973-4d68-9d3b-3f97a7f5c474"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIDziCYgklMi",
        "outputId": "7494aa96-293f-4506-8232-edb5cec33666"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(302, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preprocessing"
      ],
      "metadata": {
        "id": "4Zu67LPGkyyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 4. What is the purpose of the code that sets a list of categorical variables\n",
        "### in a dataset and then casts those variables to the object data type using the astype() function?\n",
        "\n",
        "catagorialList = ['sex','cp','fbs','restecg','exang','ca','thal']\n",
        "for item in catagorialList:\n",
        "    data[item] = data[item].astype('object') #casting to object\n",
        "\n",
        "ans = '''\n",
        "The purpose of the provided code is to prepare\n",
        "categorical variables in the dataset for use in\n",
        "machine learning algorithms by converting them\n",
        "to the object data type, which is suitable for\n",
        "representing categorical or nominal variables.\n",
        "'''\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YicdVYsQkv1B",
        "outputId": "a6b06245-7c2c-4bf5-fe79-9ddd74c83974"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The purpose of the provided code is to prepare\n",
            "categorical variables in the dataset for use in\n",
            "machine learning algorithms by converting them\n",
            "to the object data type, which is suitable for\n",
            "representing categorical or nominal variables.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " ### 5. Create more data by categorical variable into indicator variables using 'get_dummies' function\n",
        "\n",
        "data = pd.get_dummies(data, drop_first=True)"
      ],
      "metadata": {
        "id": "lo_rjkipmy9w"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 6. Explain line 3,4 and 5 and print the shape of x and y\n",
        "\n",
        "y = data['target'].values\n",
        "y = y.reshape(y.shape[0],1)\n",
        "x = data.drop(['target'],axis=1)\n",
        "\n",
        "ans = '''\n",
        "line 3: extracts the values of the 'target' column\n",
        "line 4: reshape y array into 1 dimension\n",
        "line 5: drop target in x data\n",
        "'''\n",
        "\n",
        "print(ans)\n",
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zV-OrCBm9GO",
        "outputId": "202ddd00-85d1-476f-9297-ba467f4ee4ec"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "line 3: extracts the values of the 'target' column\n",
            "line 4: reshape y array into 1 dimension\n",
            "line 5: drop target in x data\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(302, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 7. Create a simple dataset and demonstrate the normalization code on the simple dataset\n",
        "\n",
        "data = pd.DataFrame({'A': [10, 20, 30], 'B': [100, 200, 300], 'C': [1000, 2000, 3000]})\n",
        "print('Original dataset:')\n",
        "print(data)\n",
        "\n",
        "minx = np.min(data)\n",
        "maxx = np.max(data)\n",
        "data_norm = (data - minx) / (maxx - minx)\n",
        "print('\\nNormalized dataset:')\n",
        "print(data_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhIGc9WIoOX4",
        "outputId": "6c42e0be-f071-48f2-e6c0-0fc0d6ec181d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset:\n",
            "    A    B     C\n",
            "0  10  100  1000\n",
            "1  20  200  2000\n",
            "2  30  300  3000\n",
            "\n",
            "Normalized dataset:\n",
            "     A    B    C\n",
            "0  0.0  0.0  0.0\n",
            "1  0.5  0.5  0.5\n",
            "2  1.0  1.0  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 8. Describe the heart dataset after implementing the min max normalization\n",
        "\n",
        "# Normalize data (range 0 - 1)\n",
        "minx = np.min(x)\n",
        "maxx = np.max(x)\n",
        "x = (x - minx) / (maxx - minx)\n",
        "x.head()\n",
        "\n",
        "ans = '''\n",
        "After applying min-max normalization to the heart dataset,\n",
        "each feature's values are rescaled to the range between 0 and 1,\n",
        "ensuring uniformity and enabling easier interpretation and\n",
        "comparison across features.\n",
        "'''\n",
        "\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxZm5qJAoifB",
        "outputId": "ef7b7fc1-030a-4e58-ee9a-89812bd1d9b4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After applying min-max normalization to the heart dataset, \n",
            "each feature's values are rescaled to the range between 0 and 1, \n",
            "ensuring uniformity and enabling easier interpretation and \n",
            "comparison across features.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train Test Split"
      ],
      "metadata": {
        "id": "G7_wpbcfp7j3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 9. Modify the code to split the dataset into train and test (train 70%, val 20% and test 10%).\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "# re-create train and validation set\n",
        "x_train, x_val, y_train, y_val  = train_test_split(x_train, y_train, test_size=0.3/0.7, random_state=42)\n",
        "# train 70%, validation 20%, test 10%\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb5sELfrpBCU",
        "outputId": "d2bb920a-34be-4f67-c03f-743f7ce36366"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120, 21)\n",
            "(91, 21)\n",
            "(91, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Training and Evaluation"
      ],
      "metadata": {
        "id": "I3JnZnU5p_eZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 10. What is the purpose of each layer in the neural network created using the Sequential() function with 64, 32, and 1 neurons,\n",
        "### respectively, and softmax and sigmoid activation functions?\n",
        "\n",
        "model = Sequential() #Allow us to create model layer by layer\n",
        "model.add(Dense(64, input_dim=21, activation='softmax')) #Softmax turn number data into probabilities which sum to 1\n",
        "model.add(Dense(32, activation='softmax'))\n",
        "model.add(Dense(1, activation='sigmoid')) # produce probability value (number between 0 or 1)\n",
        "model.summary()\n",
        "\n",
        "ans = '''\n",
        "The purpose of each layer in the provided neural network is to\n",
        "process the input data, extract features through hidden layers,\n",
        "and produce the final predictions or outputs through the output\n",
        "layer, with specific activation functions chosen based on the\n",
        "requirements of the case study.\n",
        "'''\n",
        "\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpjPJ0tpp1yt",
        "outputId": "9894a144-9ad6-4b08-a779-4052112a3328"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                1408      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3521 (13.75 KB)\n",
            "Trainable params: 3521 (13.75 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "\n",
            "The purpose of each layer in the provided neural network is to \n",
            "process the input data, extract features through hidden layers, \n",
            "and produce the final predictions or outputs through the output \n",
            "layer, with specific activation functions chosen based on the \n",
            "requirements of the case study.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 11. This code compiles a neural network model with a mean squared error loss function, the Adam optimizer with a learning rate of 0.01,\n",
        "### and accuracy as a performance metric. What does each of these components mean, and how do they affect the model training and performance?\n",
        "\n",
        "model.compile(loss='mse',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999,epsilon=1e-07, amsgrad=False,name='Adam'),\n",
        "              metrics=['acc'])\n",
        "\n",
        "ans = '''\n",
        "1. The loss function is a measure of how well the model's predictions\n",
        "match the true labels during training.\n",
        "2. The optimizer determines how the model weights are updated during\n",
        "training to minimize the loss function.\n",
        "3. Metrics are additional performance measures used to evaluate\n",
        "the model during training and/or testing.\n",
        "'''\n",
        "\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ejkts9vqqi4",
        "outputId": "3987987a-945d-423c-8396-df15715dbef3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. The loss function is a measure of how well the model's predictions \n",
            "match the true labels during training.\n",
            "2. The optimizer determines how the model weights are updated during \n",
            "training to minimize the loss function.\n",
            "3. Metrics are additional performance measures used to evaluate \n",
            "the model during training and/or testing.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# start the model training\n",
        "output = []\n",
        "early = EarlyStopping(monitor='val_acc', patience=400, mode='auto')\n",
        "checkpoint = ModelCheckpoint(model_loc+\"heart_disease_best_model.hdf5\", monitor='val_acc', verbose=0, save_best_only=True, mode='auto', save_freq='epoch')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.01, patience=100, verbose=1, mode='auto', min_lr=0.001)\n",
        "callbacks_list = [early]\n",
        "\n",
        "output = model.fit(x_train, y_train,validation_data=(x_val,y_val), epochs=1000, batch_size=16, verbose=1, callbacks=callbacks_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbZkW8uRrU9r",
        "outputId": "eda27459-c42c-44ac-d0ed-3479700ee6a2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "8/8 [==============================] - 3s 76ms/step - loss: 0.2473 - acc: 0.5667 - val_loss: 0.2500 - val_acc: 0.5165\n",
            "Epoch 2/1000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2459 - acc: 0.5667 - val_loss: 0.2500 - val_acc: 0.5165\n",
            "Epoch 3/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.2448 - acc: 0.5667 - val_loss: 0.2497 - val_acc: 0.5165\n",
            "Epoch 4/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.2435 - acc: 0.5667 - val_loss: 0.2493 - val_acc: 0.5165\n",
            "Epoch 5/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.2412 - acc: 0.5667 - val_loss: 0.2468 - val_acc: 0.5165\n",
            "Epoch 6/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2381 - acc: 0.5667 - val_loss: 0.2422 - val_acc: 0.5165\n",
            "Epoch 7/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.2319 - acc: 0.5667 - val_loss: 0.2364 - val_acc: 0.5165\n",
            "Epoch 8/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2240 - acc: 0.5667 - val_loss: 0.2278 - val_acc: 0.5165\n",
            "Epoch 9/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.2132 - acc: 0.5750 - val_loss: 0.2186 - val_acc: 0.7253\n",
            "Epoch 10/1000\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.2004 - acc: 0.8083 - val_loss: 0.2076 - val_acc: 0.8132\n",
            "Epoch 11/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1855 - acc: 0.8667 - val_loss: 0.1967 - val_acc: 0.8132\n",
            "Epoch 12/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1707 - acc: 0.8833 - val_loss: 0.1864 - val_acc: 0.8242\n",
            "Epoch 13/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1562 - acc: 0.8917 - val_loss: 0.1775 - val_acc: 0.8132\n",
            "Epoch 14/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1428 - acc: 0.8833 - val_loss: 0.1706 - val_acc: 0.8132\n",
            "Epoch 15/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1312 - acc: 0.8917 - val_loss: 0.1653 - val_acc: 0.8022\n",
            "Epoch 16/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1213 - acc: 0.9000 - val_loss: 0.1619 - val_acc: 0.8022\n",
            "Epoch 17/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1131 - acc: 0.9083 - val_loss: 0.1588 - val_acc: 0.7912\n",
            "Epoch 18/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1045 - acc: 0.9250 - val_loss: 0.1567 - val_acc: 0.7912\n",
            "Epoch 19/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0989 - acc: 0.9167 - val_loss: 0.1552 - val_acc: 0.7802\n",
            "Epoch 20/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0922 - acc: 0.9250 - val_loss: 0.1548 - val_acc: 0.7912\n",
            "Epoch 21/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0879 - acc: 0.9250 - val_loss: 0.1542 - val_acc: 0.7912\n",
            "Epoch 22/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0839 - acc: 0.9250 - val_loss: 0.1546 - val_acc: 0.7912\n",
            "Epoch 23/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0807 - acc: 0.9250 - val_loss: 0.1547 - val_acc: 0.7692\n",
            "Epoch 24/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0772 - acc: 0.9333 - val_loss: 0.1561 - val_acc: 0.7692\n",
            "Epoch 25/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0751 - acc: 0.9333 - val_loss: 0.1566 - val_acc: 0.7692\n",
            "Epoch 26/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0731 - acc: 0.9250 - val_loss: 0.1577 - val_acc: 0.7802\n",
            "Epoch 27/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0702 - acc: 0.9333 - val_loss: 0.1582 - val_acc: 0.7802\n",
            "Epoch 28/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0691 - acc: 0.9333 - val_loss: 0.1590 - val_acc: 0.7802\n",
            "Epoch 29/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0675 - acc: 0.9333 - val_loss: 0.1595 - val_acc: 0.7692\n",
            "Epoch 30/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0659 - acc: 0.9333 - val_loss: 0.1604 - val_acc: 0.7802\n",
            "Epoch 31/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0651 - acc: 0.9333 - val_loss: 0.1587 - val_acc: 0.7802\n",
            "Epoch 32/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0634 - acc: 0.9333 - val_loss: 0.1592 - val_acc: 0.7912\n",
            "Epoch 33/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0611 - acc: 0.9333 - val_loss: 0.1603 - val_acc: 0.7802\n",
            "Epoch 34/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0587 - acc: 0.9333 - val_loss: 0.1617 - val_acc: 0.7802\n",
            "Epoch 35/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0574 - acc: 0.9500 - val_loss: 0.1621 - val_acc: 0.7912\n",
            "Epoch 36/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0564 - acc: 0.9500 - val_loss: 0.1629 - val_acc: 0.7912\n",
            "Epoch 37/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0542 - acc: 0.9500 - val_loss: 0.1617 - val_acc: 0.7912\n",
            "Epoch 38/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0530 - acc: 0.9500 - val_loss: 0.1619 - val_acc: 0.8022\n",
            "Epoch 39/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0517 - acc: 0.9500 - val_loss: 0.1614 - val_acc: 0.8022\n",
            "Epoch 40/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0501 - acc: 0.9500 - val_loss: 0.1615 - val_acc: 0.8022\n",
            "Epoch 41/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0490 - acc: 0.9500 - val_loss: 0.1612 - val_acc: 0.8022\n",
            "Epoch 42/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0474 - acc: 0.9500 - val_loss: 0.1607 - val_acc: 0.8022\n",
            "Epoch 43/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0460 - acc: 0.9500 - val_loss: 0.1592 - val_acc: 0.8022\n",
            "Epoch 44/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0424 - acc: 0.9500 - val_loss: 0.1585 - val_acc: 0.8132\n",
            "Epoch 45/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0426 - acc: 0.9500 - val_loss: 0.1600 - val_acc: 0.7802\n",
            "Epoch 46/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0385 - acc: 0.9667 - val_loss: 0.1610 - val_acc: 0.8132\n",
            "Epoch 47/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0399 - acc: 0.9583 - val_loss: 0.1614 - val_acc: 0.8022\n",
            "Epoch 48/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0385 - acc: 0.9667 - val_loss: 0.1626 - val_acc: 0.8022\n",
            "Epoch 49/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0381 - acc: 0.9583 - val_loss: 0.1625 - val_acc: 0.8022\n",
            "Epoch 50/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0371 - acc: 0.9667 - val_loss: 0.1608 - val_acc: 0.7912\n",
            "Epoch 51/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0371 - acc: 0.9583 - val_loss: 0.1604 - val_acc: 0.8132\n",
            "Epoch 52/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0358 - acc: 0.9667 - val_loss: 0.1610 - val_acc: 0.8132\n",
            "Epoch 53/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0354 - acc: 0.9667 - val_loss: 0.1625 - val_acc: 0.8022\n",
            "Epoch 54/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0358 - acc: 0.9667 - val_loss: 0.1636 - val_acc: 0.8022\n",
            "Epoch 55/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0348 - acc: 0.9667 - val_loss: 0.1640 - val_acc: 0.8022\n",
            "Epoch 56/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0346 - acc: 0.9667 - val_loss: 0.1641 - val_acc: 0.8022\n",
            "Epoch 57/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0345 - acc: 0.9667 - val_loss: 0.1634 - val_acc: 0.8022\n",
            "Epoch 58/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0339 - acc: 0.9667 - val_loss: 0.1614 - val_acc: 0.8022\n",
            "Epoch 59/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0339 - acc: 0.9667 - val_loss: 0.1610 - val_acc: 0.8022\n",
            "Epoch 60/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0334 - acc: 0.9667 - val_loss: 0.1618 - val_acc: 0.8132\n",
            "Epoch 61/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0331 - acc: 0.9667 - val_loss: 0.1636 - val_acc: 0.8132\n",
            "Epoch 62/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0331 - acc: 0.9667 - val_loss: 0.1632 - val_acc: 0.8132\n",
            "Epoch 63/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0329 - acc: 0.9667 - val_loss: 0.1629 - val_acc: 0.8132\n",
            "Epoch 64/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0319 - acc: 0.9667 - val_loss: 0.1646 - val_acc: 0.8022\n",
            "Epoch 65/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0334 - acc: 0.9667 - val_loss: 0.1651 - val_acc: 0.8132\n",
            "Epoch 66/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0307 - acc: 0.9667 - val_loss: 0.1637 - val_acc: 0.8132\n",
            "Epoch 67/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0301 - acc: 0.9667 - val_loss: 0.1657 - val_acc: 0.8132\n",
            "Epoch 68/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0284 - acc: 0.9667 - val_loss: 0.1662 - val_acc: 0.8132\n",
            "Epoch 69/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0261 - acc: 0.9750 - val_loss: 0.1666 - val_acc: 0.8022\n",
            "Epoch 70/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0242 - acc: 0.9750 - val_loss: 0.1673 - val_acc: 0.8132\n",
            "Epoch 71/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0225 - acc: 0.9833 - val_loss: 0.1678 - val_acc: 0.8132\n",
            "Epoch 72/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0263 - acc: 0.9750 - val_loss: 0.1693 - val_acc: 0.8132\n",
            "Epoch 73/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0275 - acc: 0.9750 - val_loss: 0.1724 - val_acc: 0.7802\n",
            "Epoch 74/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0259 - acc: 0.9667 - val_loss: 0.1713 - val_acc: 0.8132\n",
            "Epoch 75/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0227 - acc: 0.9750 - val_loss: 0.1708 - val_acc: 0.8132\n",
            "Epoch 76/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0210 - acc: 0.9833 - val_loss: 0.1717 - val_acc: 0.8132\n",
            "Epoch 77/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0200 - acc: 0.9833 - val_loss: 0.1729 - val_acc: 0.8022\n",
            "Epoch 78/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0197 - acc: 0.9833 - val_loss: 0.1733 - val_acc: 0.8132\n",
            "Epoch 79/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0195 - acc: 0.9833 - val_loss: 0.1746 - val_acc: 0.8022\n",
            "Epoch 80/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0193 - acc: 0.9833 - val_loss: 0.1752 - val_acc: 0.8022\n",
            "Epoch 81/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0191 - acc: 0.9833 - val_loss: 0.1746 - val_acc: 0.8132\n",
            "Epoch 82/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0194 - acc: 0.9833 - val_loss: 0.1762 - val_acc: 0.7912\n",
            "Epoch 83/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0188 - acc: 0.9833 - val_loss: 0.1755 - val_acc: 0.8132\n",
            "Epoch 84/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0187 - acc: 0.9833 - val_loss: 0.1760 - val_acc: 0.8022\n",
            "Epoch 85/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0185 - acc: 0.9833 - val_loss: 0.1764 - val_acc: 0.8022\n",
            "Epoch 86/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0187 - acc: 0.9833 - val_loss: 0.1765 - val_acc: 0.8132\n",
            "Epoch 87/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0184 - acc: 0.9833 - val_loss: 0.1788 - val_acc: 0.7912\n",
            "Epoch 88/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0183 - acc: 0.9833 - val_loss: 0.1794 - val_acc: 0.7912\n",
            "Epoch 89/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0182 - acc: 0.9833 - val_loss: 0.1790 - val_acc: 0.7912\n",
            "Epoch 90/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0183 - acc: 0.9833 - val_loss: 0.1770 - val_acc: 0.8132\n",
            "Epoch 91/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0183 - acc: 0.9833 - val_loss: 0.1791 - val_acc: 0.7912\n",
            "Epoch 92/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0179 - acc: 0.9833 - val_loss: 0.1808 - val_acc: 0.7912\n",
            "Epoch 93/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0181 - acc: 0.9833 - val_loss: 0.1804 - val_acc: 0.7912\n",
            "Epoch 94/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0178 - acc: 0.9833 - val_loss: 0.1805 - val_acc: 0.7912\n",
            "Epoch 95/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0177 - acc: 0.9833 - val_loss: 0.1810 - val_acc: 0.7912\n",
            "Epoch 96/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0179 - acc: 0.9833 - val_loss: 0.1811 - val_acc: 0.7912\n",
            "Epoch 97/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0179 - acc: 0.9833 - val_loss: 0.1851 - val_acc: 0.7912\n",
            "Epoch 98/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0178 - acc: 0.9833 - val_loss: 0.1828 - val_acc: 0.7912\n",
            "Epoch 99/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0177 - acc: 0.9833 - val_loss: 0.1819 - val_acc: 0.7912\n",
            "Epoch 100/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0176 - acc: 0.9833 - val_loss: 0.1829 - val_acc: 0.7912\n",
            "Epoch 101/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0175 - acc: 0.9833 - val_loss: 0.1857 - val_acc: 0.7912\n",
            "Epoch 102/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0176 - acc: 0.9833 - val_loss: 0.1856 - val_acc: 0.7912\n",
            "Epoch 103/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0174 - acc: 0.9833 - val_loss: 0.1836 - val_acc: 0.7912\n",
            "Epoch 104/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0175 - acc: 0.9833 - val_loss: 0.1842 - val_acc: 0.7912\n",
            "Epoch 105/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0174 - acc: 0.9833 - val_loss: 0.1861 - val_acc: 0.7912\n",
            "Epoch 106/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0175 - acc: 0.9833 - val_loss: 0.1867 - val_acc: 0.7912\n",
            "Epoch 107/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0173 - acc: 0.9833 - val_loss: 0.1857 - val_acc: 0.7912\n",
            "Epoch 108/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0174 - acc: 0.9833 - val_loss: 0.1842 - val_acc: 0.7912\n",
            "Epoch 109/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0173 - acc: 0.9833 - val_loss: 0.1863 - val_acc: 0.7912\n",
            "Epoch 110/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0173 - acc: 0.9833 - val_loss: 0.1869 - val_acc: 0.7912\n",
            "Epoch 111/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0176 - acc: 0.9833 - val_loss: 0.1857 - val_acc: 0.7912\n",
            "Epoch 112/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0172 - acc: 0.9833 - val_loss: 0.1899 - val_acc: 0.7912\n",
            "Epoch 113/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0175 - acc: 0.9833 - val_loss: 0.1883 - val_acc: 0.7912\n",
            "Epoch 114/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0170 - acc: 0.9833 - val_loss: 0.1868 - val_acc: 0.7912\n",
            "Epoch 115/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0171 - acc: 0.9833 - val_loss: 0.1883 - val_acc: 0.7912\n",
            "Epoch 116/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0170 - acc: 0.9833 - val_loss: 0.1892 - val_acc: 0.7912\n",
            "Epoch 117/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0170 - acc: 0.9833 - val_loss: 0.1891 - val_acc: 0.7912\n",
            "Epoch 118/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0170 - acc: 0.9833 - val_loss: 0.1887 - val_acc: 0.7912\n",
            "Epoch 119/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0171 - acc: 0.9833 - val_loss: 0.1903 - val_acc: 0.7912\n",
            "Epoch 120/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0170 - acc: 0.9833 - val_loss: 0.1897 - val_acc: 0.7912\n",
            "Epoch 121/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0170 - acc: 0.9833 - val_loss: 0.1875 - val_acc: 0.7912\n",
            "Epoch 122/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0170 - acc: 0.9833 - val_loss: 0.1897 - val_acc: 0.7912\n",
            "Epoch 123/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0168 - acc: 0.9833 - val_loss: 0.1910 - val_acc: 0.7912\n",
            "Epoch 124/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0169 - acc: 0.9833 - val_loss: 0.1912 - val_acc: 0.7912\n",
            "Epoch 125/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0168 - acc: 0.9833 - val_loss: 0.1898 - val_acc: 0.7912\n",
            "Epoch 126/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0168 - acc: 0.9833 - val_loss: 0.1893 - val_acc: 0.7912\n",
            "Epoch 127/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0168 - acc: 0.9833 - val_loss: 0.1895 - val_acc: 0.7912\n",
            "Epoch 128/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0168 - acc: 0.9833 - val_loss: 0.1903 - val_acc: 0.7912\n",
            "Epoch 129/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0168 - acc: 0.9833 - val_loss: 0.1907 - val_acc: 0.7912\n",
            "Epoch 130/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0168 - acc: 0.9833 - val_loss: 0.1914 - val_acc: 0.7912\n",
            "Epoch 131/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0168 - acc: 0.9833 - val_loss: 0.1910 - val_acc: 0.7912\n",
            "Epoch 132/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0168 - acc: 0.9833 - val_loss: 0.1908 - val_acc: 0.7912\n",
            "Epoch 133/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0167 - acc: 0.9833 - val_loss: 0.1913 - val_acc: 0.7912\n",
            "Epoch 134/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0167 - acc: 0.9833 - val_loss: 0.1918 - val_acc: 0.7912\n",
            "Epoch 135/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0167 - acc: 0.9833 - val_loss: 0.1909 - val_acc: 0.7912\n",
            "Epoch 136/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0167 - acc: 0.9833 - val_loss: 0.1915 - val_acc: 0.7912\n",
            "Epoch 137/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0167 - acc: 0.9833 - val_loss: 0.1927 - val_acc: 0.7912\n",
            "Epoch 138/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0167 - acc: 0.9833 - val_loss: 0.1939 - val_acc: 0.7912\n",
            "Epoch 139/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0167 - acc: 0.9833 - val_loss: 0.1928 - val_acc: 0.7912\n",
            "Epoch 140/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0168 - acc: 0.9833 - val_loss: 0.1916 - val_acc: 0.7912\n",
            "Epoch 141/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0167 - acc: 0.9833 - val_loss: 0.1938 - val_acc: 0.7912\n",
            "Epoch 142/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0166 - acc: 0.9833 - val_loss: 0.1929 - val_acc: 0.7912\n",
            "Epoch 143/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0166 - acc: 0.9833 - val_loss: 0.1925 - val_acc: 0.7912\n",
            "Epoch 144/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0167 - acc: 0.9833 - val_loss: 0.1927 - val_acc: 0.7912\n",
            "Epoch 145/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0166 - acc: 0.9833 - val_loss: 0.1920 - val_acc: 0.7912\n",
            "Epoch 146/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0166 - acc: 0.9833 - val_loss: 0.1926 - val_acc: 0.7912\n",
            "Epoch 147/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0166 - acc: 0.9833 - val_loss: 0.1931 - val_acc: 0.7912\n",
            "Epoch 148/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0166 - acc: 0.9833 - val_loss: 0.1924 - val_acc: 0.7912\n",
            "Epoch 149/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0166 - acc: 0.9833 - val_loss: 0.1930 - val_acc: 0.7912\n",
            "Epoch 150/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0165 - acc: 0.9833 - val_loss: 0.1927 - val_acc: 0.7912\n",
            "Epoch 151/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0165 - acc: 0.9833 - val_loss: 0.1930 - val_acc: 0.7912\n",
            "Epoch 152/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0165 - acc: 0.9833 - val_loss: 0.1931 - val_acc: 0.7912\n",
            "Epoch 153/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0165 - acc: 0.9833 - val_loss: 0.1940 - val_acc: 0.7912\n",
            "Epoch 154/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0165 - acc: 0.9833 - val_loss: 0.1942 - val_acc: 0.7912\n",
            "Epoch 155/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0164 - acc: 0.9833 - val_loss: 0.1941 - val_acc: 0.7912\n",
            "Epoch 156/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0164 - acc: 0.9833 - val_loss: 0.1943 - val_acc: 0.7912\n",
            "Epoch 157/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0164 - acc: 0.9833 - val_loss: 0.1949 - val_acc: 0.7912\n",
            "Epoch 158/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0164 - acc: 0.9833 - val_loss: 0.1940 - val_acc: 0.7912\n",
            "Epoch 159/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0163 - acc: 0.9833 - val_loss: 0.1953 - val_acc: 0.7912\n",
            "Epoch 160/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0157 - acc: 0.9833 - val_loss: 0.1961 - val_acc: 0.7912\n",
            "Epoch 161/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0181 - acc: 0.9750 - val_loss: 0.1943 - val_acc: 0.7912\n",
            "Epoch 162/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0090 - acc: 0.9917 - val_loss: 0.1904 - val_acc: 0.8022\n",
            "Epoch 163/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0087 - acc: 0.9917 - val_loss: 0.1910 - val_acc: 0.7912\n",
            "Epoch 164/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0087 - acc: 0.9917 - val_loss: 0.1938 - val_acc: 0.7912\n",
            "Epoch 165/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0087 - acc: 0.9917 - val_loss: 0.1940 - val_acc: 0.7912\n",
            "Epoch 166/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0086 - acc: 0.9917 - val_loss: 0.1942 - val_acc: 0.7912\n",
            "Epoch 167/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0086 - acc: 0.9917 - val_loss: 0.1936 - val_acc: 0.7912\n",
            "Epoch 168/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0086 - acc: 0.9917 - val_loss: 0.1938 - val_acc: 0.7912\n",
            "Epoch 169/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0086 - acc: 0.9917 - val_loss: 0.1946 - val_acc: 0.7912\n",
            "Epoch 170/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0086 - acc: 0.9917 - val_loss: 0.1958 - val_acc: 0.7912\n",
            "Epoch 171/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0085 - acc: 0.9917 - val_loss: 0.1954 - val_acc: 0.7912\n",
            "Epoch 172/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0085 - acc: 0.9917 - val_loss: 0.1951 - val_acc: 0.7912\n",
            "Epoch 173/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0085 - acc: 0.9917 - val_loss: 0.1954 - val_acc: 0.7912\n",
            "Epoch 174/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0085 - acc: 0.9917 - val_loss: 0.1956 - val_acc: 0.7912\n",
            "Epoch 175/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0085 - acc: 0.9917 - val_loss: 0.1956 - val_acc: 0.7912\n",
            "Epoch 176/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0085 - acc: 0.9917 - val_loss: 0.1957 - val_acc: 0.7912\n",
            "Epoch 177/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0085 - acc: 0.9917 - val_loss: 0.1956 - val_acc: 0.7912\n",
            "Epoch 178/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0085 - acc: 0.9917 - val_loss: 0.1956 - val_acc: 0.7912\n",
            "Epoch 179/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0085 - acc: 0.9917 - val_loss: 0.1956 - val_acc: 0.7912\n",
            "Epoch 180/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0085 - acc: 0.9917 - val_loss: 0.1960 - val_acc: 0.7912\n",
            "Epoch 181/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1955 - val_acc: 0.7912\n",
            "Epoch 182/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1956 - val_acc: 0.7912\n",
            "Epoch 183/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1959 - val_acc: 0.7912\n",
            "Epoch 184/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1962 - val_acc: 0.7912\n",
            "Epoch 185/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1953 - val_acc: 0.7912\n",
            "Epoch 186/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1953 - val_acc: 0.7912\n",
            "Epoch 187/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1962 - val_acc: 0.7912\n",
            "Epoch 188/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1965 - val_acc: 0.7912\n",
            "Epoch 189/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1966 - val_acc: 0.7912\n",
            "Epoch 190/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1965 - val_acc: 0.7912\n",
            "Epoch 191/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1965 - val_acc: 0.7912\n",
            "Epoch 192/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1963 - val_acc: 0.7912\n",
            "Epoch 193/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1964 - val_acc: 0.7912\n",
            "Epoch 194/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1965 - val_acc: 0.7912\n",
            "Epoch 195/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1962 - val_acc: 0.7912\n",
            "Epoch 196/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1964 - val_acc: 0.7912\n",
            "Epoch 197/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1967 - val_acc: 0.7912\n",
            "Epoch 198/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1964 - val_acc: 0.7912\n",
            "Epoch 199/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1968 - val_acc: 0.7912\n",
            "Epoch 200/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1972 - val_acc: 0.7912\n",
            "Epoch 201/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1978 - val_acc: 0.7912\n",
            "Epoch 202/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1974 - val_acc: 0.7912\n",
            "Epoch 203/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1971 - val_acc: 0.7912\n",
            "Epoch 204/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.1977 - val_acc: 0.7912\n",
            "Epoch 205/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1971 - val_acc: 0.7912\n",
            "Epoch 206/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1970 - val_acc: 0.7912\n",
            "Epoch 207/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1971 - val_acc: 0.7912\n",
            "Epoch 208/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1973 - val_acc: 0.7912\n",
            "Epoch 209/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1978 - val_acc: 0.7912\n",
            "Epoch 210/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1976 - val_acc: 0.7912\n",
            "Epoch 211/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1975 - val_acc: 0.7912\n",
            "Epoch 212/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1976 - val_acc: 0.7912\n",
            "Epoch 213/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1975 - val_acc: 0.7912\n",
            "Epoch 214/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1979 - val_acc: 0.7912\n",
            "Epoch 215/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1981 - val_acc: 0.7912\n",
            "Epoch 216/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1979 - val_acc: 0.7912\n",
            "Epoch 217/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1979 - val_acc: 0.7912\n",
            "Epoch 218/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1981 - val_acc: 0.7912\n",
            "Epoch 219/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1981 - val_acc: 0.7912\n",
            "Epoch 220/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1983 - val_acc: 0.7912\n",
            "Epoch 221/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1982 - val_acc: 0.7912\n",
            "Epoch 222/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1981 - val_acc: 0.7912\n",
            "Epoch 223/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1983 - val_acc: 0.7912\n",
            "Epoch 224/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1980 - val_acc: 0.7912\n",
            "Epoch 225/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1983 - val_acc: 0.7912\n",
            "Epoch 226/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1981 - val_acc: 0.7912\n",
            "Epoch 227/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1983 - val_acc: 0.7912\n",
            "Epoch 228/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1985 - val_acc: 0.7912\n",
            "Epoch 229/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1988 - val_acc: 0.7912\n",
            "Epoch 230/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1988 - val_acc: 0.7912\n",
            "Epoch 231/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1986 - val_acc: 0.7912\n",
            "Epoch 232/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1987 - val_acc: 0.7912\n",
            "Epoch 233/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1988 - val_acc: 0.7912\n",
            "Epoch 234/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1989 - val_acc: 0.7912\n",
            "Epoch 235/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.1989 - val_acc: 0.7912\n",
            "Epoch 236/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.1992 - val_acc: 0.7912\n",
            "Epoch 237/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.1994 - val_acc: 0.7912\n",
            "Epoch 238/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.1992 - val_acc: 0.7912\n",
            "Epoch 239/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.1991 - val_acc: 0.7912\n",
            "Epoch 240/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.1992 - val_acc: 0.7912\n",
            "Epoch 241/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.1994 - val_acc: 0.7912\n",
            "Epoch 242/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.1994 - val_acc: 0.7912\n",
            "Epoch 243/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.1995 - val_acc: 0.7912\n",
            "Epoch 244/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.1997 - val_acc: 0.7912\n",
            "Epoch 245/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.1997 - val_acc: 0.7912\n",
            "Epoch 246/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.1997 - val_acc: 0.7912\n",
            "Epoch 247/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.1997 - val_acc: 0.7912\n",
            "Epoch 248/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.1998 - val_acc: 0.7912\n",
            "Epoch 249/1000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.1998 - val_acc: 0.7912\n",
            "Epoch 250/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.1999 - val_acc: 0.7912\n",
            "Epoch 251/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.2000 - val_acc: 0.7912\n",
            "Epoch 252/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.2001 - val_acc: 0.7912\n",
            "Epoch 253/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.2002 - val_acc: 0.7912\n",
            "Epoch 254/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.2004 - val_acc: 0.7912\n",
            "Epoch 255/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.2005 - val_acc: 0.7912\n",
            "Epoch 256/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.2007 - val_acc: 0.7912\n",
            "Epoch 257/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.2007 - val_acc: 0.7912\n",
            "Epoch 258/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.2007 - val_acc: 0.7802\n",
            "Epoch 259/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.2009 - val_acc: 0.7802\n",
            "Epoch 260/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.2012 - val_acc: 0.7802\n",
            "Epoch 261/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.2013 - val_acc: 0.7802\n",
            "Epoch 262/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.2013 - val_acc: 0.7802\n",
            "Epoch 263/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.2016 - val_acc: 0.7802\n",
            "Epoch 264/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.2019 - val_acc: 0.7802\n",
            "Epoch 265/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.2019 - val_acc: 0.7802\n",
            "Epoch 266/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.2021 - val_acc: 0.7802\n",
            "Epoch 267/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.2021 - val_acc: 0.7802\n",
            "Epoch 268/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.2024 - val_acc: 0.7802\n",
            "Epoch 269/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.2023 - val_acc: 0.7802\n",
            "Epoch 270/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2026 - val_acc: 0.7802\n",
            "Epoch 271/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2027 - val_acc: 0.7802\n",
            "Epoch 272/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2032 - val_acc: 0.7802\n",
            "Epoch 273/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2034 - val_acc: 0.7802\n",
            "Epoch 274/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2035 - val_acc: 0.7802\n",
            "Epoch 275/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2038 - val_acc: 0.7802\n",
            "Epoch 276/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2038 - val_acc: 0.7802\n",
            "Epoch 277/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2039 - val_acc: 0.7802\n",
            "Epoch 278/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2039 - val_acc: 0.7802\n",
            "Epoch 279/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2040 - val_acc: 0.7802\n",
            "Epoch 280/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2042 - val_acc: 0.7802\n",
            "Epoch 281/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2044 - val_acc: 0.7802\n",
            "Epoch 282/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2042 - val_acc: 0.7802\n",
            "Epoch 283/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2043 - val_acc: 0.7802\n",
            "Epoch 284/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2042 - val_acc: 0.7802\n",
            "Epoch 285/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2045 - val_acc: 0.7802\n",
            "Epoch 286/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2048 - val_acc: 0.7802\n",
            "Epoch 287/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2048 - val_acc: 0.7802\n",
            "Epoch 288/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2046 - val_acc: 0.7802\n",
            "Epoch 289/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2045 - val_acc: 0.7802\n",
            "Epoch 290/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2047 - val_acc: 0.7802\n",
            "Epoch 291/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2050 - val_acc: 0.7802\n",
            "Epoch 292/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2051 - val_acc: 0.7802\n",
            "Epoch 293/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2048 - val_acc: 0.7802\n",
            "Epoch 294/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2047 - val_acc: 0.7802\n",
            "Epoch 295/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2052 - val_acc: 0.7802\n",
            "Epoch 296/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2048 - val_acc: 0.7802\n",
            "Epoch 297/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.2050 - val_acc: 0.7802\n",
            "Epoch 298/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.2059 - val_acc: 0.7802\n",
            "Epoch 299/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.2056 - val_acc: 0.7802\n",
            "Epoch 300/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.2053 - val_acc: 0.7802\n",
            "Epoch 301/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.2050 - val_acc: 0.7802\n",
            "Epoch 302/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.2049 - val_acc: 0.7802\n",
            "Epoch 303/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.2048 - val_acc: 0.7802\n",
            "Epoch 304/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.2049 - val_acc: 0.7802\n",
            "Epoch 305/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.2048 - val_acc: 0.7802\n",
            "Epoch 306/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.2047 - val_acc: 0.7802\n",
            "Epoch 307/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.2049 - val_acc: 0.7802\n",
            "Epoch 308/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.2047 - val_acc: 0.7802\n",
            "Epoch 309/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.2049 - val_acc: 0.7802\n",
            "Epoch 310/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.2052 - val_acc: 0.7802\n",
            "Epoch 311/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.2053 - val_acc: 0.7802\n",
            "Epoch 312/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.2055 - val_acc: 0.7802\n",
            "Epoch 313/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.2054 - val_acc: 0.7802\n",
            "Epoch 314/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.2052 - val_acc: 0.7802\n",
            "Epoch 315/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.2059 - val_acc: 0.7802\n",
            "Epoch 316/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.2051 - val_acc: 0.7802\n",
            "Epoch 317/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0079 - acc: 0.9917 - val_loss: 0.2046 - val_acc: 0.7802\n",
            "Epoch 318/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0079 - acc: 0.9917 - val_loss: 0.2049 - val_acc: 0.7802\n",
            "Epoch 319/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0079 - acc: 0.9917 - val_loss: 0.2050 - val_acc: 0.7802\n",
            "Epoch 320/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0079 - acc: 0.9917 - val_loss: 0.2041 - val_acc: 0.7802\n",
            "Epoch 321/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0079 - acc: 0.9917 - val_loss: 0.2030 - val_acc: 0.7802\n",
            "Epoch 322/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0079 - acc: 0.9917 - val_loss: 0.2030 - val_acc: 0.7802\n",
            "Epoch 323/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0079 - acc: 0.9917 - val_loss: 0.2038 - val_acc: 0.7802\n",
            "Epoch 324/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0079 - acc: 0.9917 - val_loss: 0.2037 - val_acc: 0.7802\n",
            "Epoch 325/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0079 - acc: 0.9917 - val_loss: 0.2038 - val_acc: 0.7802\n",
            "Epoch 326/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0079 - acc: 0.9917 - val_loss: 0.2042 - val_acc: 0.7802\n",
            "Epoch 327/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0079 - acc: 0.9917 - val_loss: 0.2034 - val_acc: 0.7802\n",
            "Epoch 328/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0079 - acc: 0.9917 - val_loss: 0.2033 - val_acc: 0.7802\n",
            "Epoch 329/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0079 - acc: 0.9917 - val_loss: 0.2035 - val_acc: 0.7802\n",
            "Epoch 330/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0079 - acc: 0.9917 - val_loss: 0.2033 - val_acc: 0.7802\n",
            "Epoch 331/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0079 - acc: 0.9917 - val_loss: 0.2024 - val_acc: 0.7802\n",
            "Epoch 332/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0078 - acc: 0.9917 - val_loss: 0.2025 - val_acc: 0.7802\n",
            "Epoch 333/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0078 - acc: 0.9917 - val_loss: 0.2020 - val_acc: 0.7802\n",
            "Epoch 334/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0078 - acc: 0.9917 - val_loss: 0.2019 - val_acc: 0.7802\n",
            "Epoch 335/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0078 - acc: 0.9917 - val_loss: 0.2014 - val_acc: 0.7802\n",
            "Epoch 336/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0078 - acc: 0.9917 - val_loss: 0.2012 - val_acc: 0.7802\n",
            "Epoch 337/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0078 - acc: 0.9917 - val_loss: 0.1998 - val_acc: 0.7912\n",
            "Epoch 338/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0078 - acc: 0.9917 - val_loss: 0.1995 - val_acc: 0.7912\n",
            "Epoch 339/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0078 - acc: 0.9917 - val_loss: 0.1997 - val_acc: 0.7912\n",
            "Epoch 340/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0078 - acc: 0.9917 - val_loss: 0.1987 - val_acc: 0.7912\n",
            "Epoch 341/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0078 - acc: 0.9917 - val_loss: 0.1990 - val_acc: 0.7912\n",
            "Epoch 342/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0077 - acc: 0.9917 - val_loss: 0.1989 - val_acc: 0.7912\n",
            "Epoch 343/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0077 - acc: 0.9917 - val_loss: 0.1983 - val_acc: 0.7912\n",
            "Epoch 344/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0077 - acc: 0.9917 - val_loss: 0.1972 - val_acc: 0.7912\n",
            "Epoch 345/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0077 - acc: 0.9917 - val_loss: 0.1974 - val_acc: 0.7912\n",
            "Epoch 346/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0077 - acc: 0.9917 - val_loss: 0.1967 - val_acc: 0.7912\n",
            "Epoch 347/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0077 - acc: 0.9917 - val_loss: 0.1977 - val_acc: 0.7912\n",
            "Epoch 348/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0077 - acc: 0.9917 - val_loss: 0.1972 - val_acc: 0.7912\n",
            "Epoch 349/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0077 - acc: 0.9917 - val_loss: 0.1967 - val_acc: 0.7912\n",
            "Epoch 350/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0077 - acc: 0.9917 - val_loss: 0.1952 - val_acc: 0.7912\n",
            "Epoch 351/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - acc: 0.9917 - val_loss: 0.1944 - val_acc: 0.8022\n",
            "Epoch 352/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - acc: 0.9917 - val_loss: 0.1943 - val_acc: 0.8022\n",
            "Epoch 353/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - acc: 0.9917 - val_loss: 0.1943 - val_acc: 0.8022\n",
            "Epoch 354/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0076 - acc: 0.9917 - val_loss: 0.1941 - val_acc: 0.8022\n",
            "Epoch 355/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - acc: 0.9917 - val_loss: 0.1935 - val_acc: 0.8022\n",
            "Epoch 356/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - acc: 0.9917 - val_loss: 0.1933 - val_acc: 0.8022\n",
            "Epoch 357/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - acc: 0.9917 - val_loss: 0.1936 - val_acc: 0.8022\n",
            "Epoch 358/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0075 - acc: 0.9917 - val_loss: 0.1929 - val_acc: 0.8022\n",
            "Epoch 359/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - acc: 0.9917 - val_loss: 0.1930 - val_acc: 0.8022\n",
            "Epoch 360/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0075 - acc: 0.9917 - val_loss: 0.1923 - val_acc: 0.8022\n",
            "Epoch 361/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0075 - acc: 0.9917 - val_loss: 0.1925 - val_acc: 0.8022\n",
            "Epoch 362/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - acc: 0.9917 - val_loss: 0.1924 - val_acc: 0.8022\n",
            "Epoch 363/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - acc: 0.9917 - val_loss: 0.1920 - val_acc: 0.8022\n",
            "Epoch 364/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - acc: 0.9917 - val_loss: 0.1919 - val_acc: 0.8022\n",
            "Epoch 365/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - acc: 0.9917 - val_loss: 0.1916 - val_acc: 0.8022\n",
            "Epoch 366/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0074 - acc: 0.9917 - val_loss: 0.1918 - val_acc: 0.8022\n",
            "Epoch 367/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0073 - acc: 0.9917 - val_loss: 0.1927 - val_acc: 0.8022\n",
            "Epoch 368/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0074 - acc: 0.9917 - val_loss: 0.1916 - val_acc: 0.8022\n",
            "Epoch 369/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0073 - acc: 0.9917 - val_loss: 0.1906 - val_acc: 0.8022\n",
            "Epoch 370/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0073 - acc: 0.9917 - val_loss: 0.1906 - val_acc: 0.8022\n",
            "Epoch 371/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0073 - acc: 0.9917 - val_loss: 0.1905 - val_acc: 0.8022\n",
            "Epoch 372/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0073 - acc: 0.9917 - val_loss: 0.1897 - val_acc: 0.8022\n",
            "Epoch 373/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0072 - acc: 0.9917 - val_loss: 0.1893 - val_acc: 0.8022\n",
            "Epoch 374/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0072 - acc: 0.9917 - val_loss: 0.1895 - val_acc: 0.8022\n",
            "Epoch 375/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0072 - acc: 0.9917 - val_loss: 0.1894 - val_acc: 0.8022\n",
            "Epoch 376/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0072 - acc: 0.9917 - val_loss: 0.1893 - val_acc: 0.8022\n",
            "Epoch 377/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0072 - acc: 0.9917 - val_loss: 0.1885 - val_acc: 0.8022\n",
            "Epoch 378/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0071 - acc: 0.9917 - val_loss: 0.1889 - val_acc: 0.8022\n",
            "Epoch 379/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0071 - acc: 0.9917 - val_loss: 0.1883 - val_acc: 0.8022\n",
            "Epoch 380/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0071 - acc: 0.9917 - val_loss: 0.1887 - val_acc: 0.8022\n",
            "Epoch 381/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0071 - acc: 0.9917 - val_loss: 0.1873 - val_acc: 0.8022\n",
            "Epoch 382/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0070 - acc: 0.9917 - val_loss: 0.1877 - val_acc: 0.8022\n",
            "Epoch 383/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0070 - acc: 0.9917 - val_loss: 0.1874 - val_acc: 0.8022\n",
            "Epoch 384/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0070 - acc: 0.9917 - val_loss: 0.1863 - val_acc: 0.8022\n",
            "Epoch 385/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0069 - acc: 0.9917 - val_loss: 0.1871 - val_acc: 0.8022\n",
            "Epoch 386/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0069 - acc: 0.9917 - val_loss: 0.1868 - val_acc: 0.8022\n",
            "Epoch 387/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0069 - acc: 0.9917 - val_loss: 0.1866 - val_acc: 0.8022\n",
            "Epoch 388/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0069 - acc: 0.9917 - val_loss: 0.1854 - val_acc: 0.8132\n",
            "Epoch 389/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0068 - acc: 0.9917 - val_loss: 0.1845 - val_acc: 0.8132\n",
            "Epoch 390/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0068 - acc: 0.9917 - val_loss: 0.1845 - val_acc: 0.8132\n",
            "Epoch 391/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0068 - acc: 0.9917 - val_loss: 0.1845 - val_acc: 0.8132\n",
            "Epoch 392/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0067 - acc: 0.9917 - val_loss: 0.1840 - val_acc: 0.8132\n",
            "Epoch 393/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0067 - acc: 0.9917 - val_loss: 0.1836 - val_acc: 0.8132\n",
            "Epoch 394/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0067 - acc: 0.9917 - val_loss: 0.1837 - val_acc: 0.8132\n",
            "Epoch 395/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0067 - acc: 0.9917 - val_loss: 0.1837 - val_acc: 0.8132\n",
            "Epoch 396/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0066 - acc: 0.9917 - val_loss: 0.1841 - val_acc: 0.8132\n",
            "Epoch 397/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0066 - acc: 0.9917 - val_loss: 0.1841 - val_acc: 0.8132\n",
            "Epoch 398/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0067 - acc: 0.9917 - val_loss: 0.1843 - val_acc: 0.8132\n",
            "Epoch 399/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0066 - acc: 0.9917 - val_loss: 0.1842 - val_acc: 0.8132\n",
            "Epoch 400/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0065 - acc: 0.9917 - val_loss: 0.1838 - val_acc: 0.8132\n",
            "Epoch 401/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0064 - acc: 0.9917 - val_loss: 0.1839 - val_acc: 0.8132\n",
            "Epoch 402/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0063 - acc: 0.9917 - val_loss: 0.1843 - val_acc: 0.8132\n",
            "Epoch 403/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0062 - acc: 0.9917 - val_loss: 0.1848 - val_acc: 0.8132\n",
            "Epoch 404/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0061 - acc: 0.9917 - val_loss: 0.1849 - val_acc: 0.8132\n",
            "Epoch 405/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0062 - acc: 0.9917 - val_loss: 0.1848 - val_acc: 0.8132\n",
            "Epoch 406/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0060 - acc: 0.9917 - val_loss: 0.1851 - val_acc: 0.8132\n",
            "Epoch 407/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0062 - acc: 0.9917 - val_loss: 0.1849 - val_acc: 0.8132\n",
            "Epoch 408/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0110 - acc: 0.9833 - val_loss: 0.1873 - val_acc: 0.8132\n",
            "Epoch 409/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0322 - acc: 0.9500 - val_loss: 0.2035 - val_acc: 0.7912\n",
            "Epoch 410/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0089 - acc: 0.9833 - val_loss: 0.1996 - val_acc: 0.7912\n",
            "Epoch 411/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0168 - acc: 0.9833 - val_loss: 0.2140 - val_acc: 0.7802\n",
            "Epoch 412/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0201 - acc: 0.9667 - val_loss: 0.1934 - val_acc: 0.7912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 12. What does the plot generated by this code represent?\n",
        "\n",
        "plt.plot(output.history['acc'])\n",
        "plt.plot(output.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "#plt.savefig('Accuracy.png',dpi=100) #to save the image\n",
        "plt.show()\n",
        "\n",
        "ans = '''\n",
        "The plot shows that the accuracy of the train model achieve consistency\n",
        "nearly 1.0 at each epoch while the accuracy of test model achieve\n",
        "consistency of nearly 0.8 along the epoch.\n",
        "'''\n",
        "\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "JQfNUFV7rgdI",
        "outputId": "1da49fd3-32c5-41d6-9c02-94cd62c35559"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The plot shows that the accuracy of the train model achieve consistency \n",
            "nearly 1.0 at each epoch while the accuracy of test model achieve\n",
            "consistency of nearly 0.8 along the epoch.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 13. Plot code for the model loss. You can refer to the plot code for model accuracy above.\n",
        "\n",
        "plt.plot(output.history['loss'])  # Plot training loss\n",
        "plt.plot(output.history['val_loss'])  # Plot validation loss\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "0PDjfZrPtDqg",
        "outputId": "17d73eda-11a5-4fb0-ba20-2afd09216a9e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 14. What is the purpose of evaluating the model on the test dataset?\n",
        "\n",
        "#model.load_weights(model_loc+\"heart_disease_best_model.hdf5\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "# print(\"\\n%s: %.2f%%\" % (model.metrics_names[0], scores[0]))\n",
        "print(\"loss:\", round(scores[0],2))\n",
        "\n",
        "ans = '''\n",
        "Evaluating the model on the test dataset provides insight\n",
        "into its generalization performance, helps detect overfitting,\n",
        "and reports final performance metrics such as accuracy and loss.\n",
        "'''\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olzs-1mQtZeC",
        "outputId": "b9f5aa07-bd0a-40f1-cd91-7cd804bd4928"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1718 - acc: 0.8132\n",
            "\n",
            "acc: 81.32%\n",
            "loss: 0.17\n",
            "\n",
            "Evaluating the model on the test dataset provides insight \n",
            "into its generalization performance, helps detect overfitting,\n",
            "and reports final performance metrics such as accuracy and loss.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Display detailed prediction\n",
        "pred = model.predict(x_test)\n",
        "y = np.round(pred).astype(\"int16\")\n",
        "idx = 0\n",
        "ps = 0\n",
        "fl = 0\n",
        "for x in pred:\n",
        "    if y_test[idx]==y[idx]:\n",
        "        print(\"\\033[30mNo:\",idx+1,\"Actual:\",y_test[idx],\" Predicted:\",y[idx],\"Result: \\033[92mPass\")\n",
        "        ps = ps+1\n",
        "    else:\n",
        "        print(\"\\033[30mNo:\",idx+1,\"Actual:\",y_test[idx],\" Predicted:\",y[idx],\" Result: \\033[91mFail\")\n",
        "        fl = fl+1\n",
        "    idx = idx + 1\n",
        "print(\"\\033[30mRight Prediction :\",ps, \"Wrong Prediction :\",fl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3dhY6gxuMOa",
        "outputId": "802a36cb-792b-4767-b19a-fa150ffec735"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 3ms/step\n",
            "\u001b[30mNo: 1 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 2 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 3 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 4 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 5 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 6 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 7 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 8 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 9 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 10 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 11 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 12 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 13 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 14 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 15 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 16 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 17 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 18 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 19 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 20 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 21 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 22 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 23 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 24 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 25 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 26 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 27 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 28 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 29 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 30 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 31 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 32 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 33 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 34 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 35 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 36 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 37 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 38 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 39 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 40 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 41 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 42 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 43 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 44 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 45 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 46 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 47 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 48 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 49 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 50 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 51 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 52 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 53 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 54 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 55 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 56 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 57 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 58 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 59 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 60 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 61 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 62 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 63 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 64 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 65 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 66 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 67 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 68 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 69 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 70 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 71 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 72 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 73 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 74 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 75 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 76 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 77 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 78 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 79 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 80 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 81 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 82 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 83 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 84 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 85 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 86 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 87 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 88 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 89 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 90 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 91 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mRight Prediction : 74 Wrong Prediction : 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 15. What is Confusion Matrix and why you need it? Explain TP, FP, FN, TN.\n",
        "\n",
        "ans = '''\n",
        "1. Confusion Matrix is a table that summarizes the performance of a\n",
        "classification model by comparing predicted labels with true labels,\n",
        "helping to evaluate the model's accuracy and identify errors.\n",
        "2. TP: The number of correctly predicted positive instances.\n",
        "3. FP: The number of incorrectly predicted positive instances.\n",
        "4. FN: The number of incorrectly predicted negative instances.\n",
        "5. TN: The number of correctly predicted negative instances.\n",
        "'''\n",
        "print(ans)\n",
        "\n",
        "### 16. Explain the classification report produce.\n",
        "\n",
        "y_pred = y\n",
        "y_true = y_test\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
        "#cm = confusion_matrix(y_true, y_pred, labels=labels.astype('int'))\n",
        "f, ax=plt.subplots(figsize=(5,5))\n",
        "sns.heatmap(cm,annot=True,linewidths=1.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
        "plt.xlabel(\"y_pred\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.show()\n",
        "print()\n",
        "print(classification_report(y_true, y_pred, labels=[0,1]))\n",
        "\n",
        "ans = '''\n",
        "The classification report summarizes key metrics such as precision,\n",
        "recall, F1-score, and support for each class in a classification problem,\n",
        "providing insights into the model's performance and helping to assess\n",
        "its effectiveness in correctly classifying instances.\n",
        "'''\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899
        },
        "id": "BGlrtaMMuRaF",
        "outputId": "21f3ffb7-b977-4bd6-ea30-77f5d043ad3d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. Confusion Matrix is a table that summarizes the performance of a \n",
            "classification model by comparing predicted labels with true labels, \n",
            "helping to evaluate the model's accuracy and identify errors.\n",
            "2. TP: The number of correctly predicted positive instances.\n",
            "3. FP: The number of incorrectly predicted positive instances.\n",
            "4. FN: The number of incorrectly predicted negative instances.\n",
            "5. TN: The number of correctly predicted negative instances.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAAHACAYAAAAhsCaSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAp1UlEQVR4nO3de3RU9bn/8c8EkgkhJCEQcoEgCAgCBjRyIFqpQgRCfxgkXqpWg1KtNqIktWp6VMDKCepRkBrQKnJRESoVFHoUAZtAj9xMBcEWFES5JuCFhAQZksz+/WE7p1MCZGAnk3z3++Xaa7Hvz6zl4uF59ve7t8uyLEsAABgkJNgBAABgN5IbAMA4JDcAgHFIbgAA45DcAADGIbkBAIxDcgMAGIfkBgAwDskNAGCclsEOoEG4XMGOAADsZfPLpKq//sK2a4W2P9+2a9nFzOQGADg9b22wI2hQRie37677cbBDgKHaLi72W0/vNCxIkcB0q/a9H+wQmiWjkxsA4BQsb7AjaFAkNwBwIq/ZyY3RkgAA41C5AYADWbQlAQDGoS0JAEDzQuUGAE5EWxIAYBzDJ3HTlgQAGIfKDQCciLYkAMA4jJYEAKB5oXIDAAdiEjcAwDy0JQEAaF6o3ADAiWhLAgCMwyRuAACaFyo3AHAi2pIAAOMwWhIAgOaFyg0AnIi2JADAOLQlAQBoXqjcAMCBLMvseW4kNwBwIsOfudGWBAAYh8oNAJzI8AElJDcAcCLakgAANC9UbgDgRIZ/FYDkBgBORFsSAAD7TZ06VS6XSxMmTPBtO378uHJyctSuXTtFRkYqKytLZWVlAV+b5AYATuT12rechU2bNunFF19USkqK3/bc3FwtW7ZMb775poqLi3XgwAGNGTMm4OuT3ADAiSyvfUuAKisrdcstt+ill15S27ZtfdvLy8s1e/ZsPfvssxoyZIhSU1M1Z84cffjhh1q/fn1A9yC5AQDOicfjUUVFhd/i8XhOeXxOTo5+8pOfKD093W97SUmJqqur/bb36tVLnTt31rp16wKKieQGAE5kY1uyoKBA0dHRfktBQUGdt124cKH++te/1rm/tLRUYWFhiomJ8dseHx+v0tLSgH4eoyUBwIlsfENJfn6+8vLy/La53e6Tjtu7d6/uv/9+rVy5UuHh4bbdvy4kNwDAOXG73XUms39XUlKiQ4cO6ZJLLvFtq62t1Zo1a/T8889rxYoVOnHihI4cOeJXvZWVlSkhISGgmEhuAOBAwfjkzdChQ7V161a/bbfffrt69eqlhx56SMnJyQoNDdXq1auVlZUlSdqxY4f27NmjtLS0gO5FcgMAJwrCi5PbtGmjvn37+m1r3bq12rVr59s+btw45eXlKTY2VlFRURo/frzS0tI0aNCggO5FcgMANBnTpk1TSEiIsrKy5PF4NHz4cM2cOTPg65DcAMCJmsjrt4qKivzWw8PDVVhYqMLCwnO6LskNAJzI8O+5Mc8NAGAcKjcAcKIm0pZsKCQ3AHAi2pIAADQvVG4A4ES0JQEAxqEtCQBA80LlBgBOZHjlRnIDACcy/JkbbUkAgHGo3ADAiWhLAgCMQ1sSAIDmhcoNAJyItiQAwDi0JQEAaF6o3ADAiWhLAgCMY3hyoy0JADAOlRsAOJFlBTuCBkVyAwAnoi0JAEDzQuUGAE5keOVGcgMAJ2ISNwAAzQuVGwA4EW1JAIBxDJ8KQFsSAGAcKjcAcCLakgAA4xie3GhLAgCMQ+UGAE5k+Dw3khsAOJDlZbQkAADNCpUbADiR4QNKSG4A4ESGP3OjLQkAMA7JDQCcyGvZtwRg1qxZSklJUVRUlKKiopSWlqZ3333Xt//KK6+Uy+XyW+6+++6Afx5tSQBwoiA9c+vUqZOmTp2qHj16yLIszZs3T5mZmfr444/Vp08fSdKdd96pxx9/3HdOREREwPchuQEAGs2oUaP81qdMmaJZs2Zp/fr1vuQWERGhhISEc7oPbUkAcCKv17bF4/GooqLCb/F4PGcMoba2VgsXLlRVVZXS0tJ8219//XW1b99effv2VX5+vo4dOxbwzyO5AYATWZZtS0FBgaKjo/2WgoKCU95669atioyMlNvt1t13360lS5aod+/ekqSbb75Zr732mv785z8rPz9fr776qn72s58F/PNclmXgR31cLknSd9f9OMiBwFRtFxf7rad3GhakSGC6Vfve/+EPNv9VfWz6L2y7Vot7ZpxUqbndbrnd7jqPP3HihPbs2aPy8nItXrxYL7/8soqLi30J7l998MEHGjp0qHbu3Klu3brVOyaeuTlI2LBr5B6WqRZxP/Sya/d9qe/fnKeazRt/OCA0TK1uu0dhlw+RKzRM1Zs36tjL02WVfxfEqNFcXTSwr274xfXqkdJD7ePb6bGfT9KHK9ZJklq0bKHbfz1WA4cMUELnRFUdrdLHaz/Wy1Nn65uyb4McuUPYOKDkdImsLmFhYerevbskKTU1VZs2bdJzzz2nF1988aRjBw4cKEkBJzfakg5ifXNY37/+e1U8dJcqHv6Fqrf9VZEPTVFIpy6SpIixOQq79DJVPTtJRyfer5DY9op84PHTXxQ4hfBW4fri71/od488X8c+t3r07a7XnlugezJyNPnOx9WpWyc9/srkIETqUEGaClBnKP94bleXzZs3S5ISExMDuiaVm4NUl6zzWz/+xmy5h2Wq5QW9deLbwwobMlJVzz2hmm0fS5KqCp9U9HPz1aJHb9V+/rdghIxmbFPRR9pU9FGd+6qOHtNDt+T7bXv+0UIVLv+dOiTF6dCBw40RIoIgPz9fGRkZ6ty5s44ePaoFCxaoqKhIK1as0K5du7RgwQKNHDlS7dq10yeffKLc3FwNHjxYKSkpAd2H5OZUISEKHXSlXO5w1Xz2qVqef4FcLUNV80mJ7xDvgT2qPVyqlheQ3NDwWrdpLa/Xq8qKqmCH4gxBev3WoUOHdNttt+ngwYOKjo5WSkqKVqxYoauvvlp79+7VqlWrNH36dFVVVSk5OVlZWVl65JFHAr5PUJPb119/rVdeeUXr1q1TaWmpJCkhIUGXXXaZxo4dq7i4uGCGZ6SQzl0VNWWmFBom6/j3qnz6UXn3faUWXbrLqj4h61il3/FW+XcKiYkNUrRwilB3qH6eP05/frtIxyoDH/aNsxCkT97Mnj37lPuSk5NVXFx8yv2BCFpy27Rpk4YPH66IiAilp6frggsukCSVlZVpxowZmjp1qlasWKFLL730tNfxeDwnj9L5x4KTeQ/sVcWvfy5XRGuFDvqxWt+br6MT7w92WHCwFi1b6NFZ/ymXS3ruN78LdjgwRNCS2/jx43X99dfrhRdekOsfQ/f/ybIs3X333Ro/frzWrVt3iiv8oKCgQJMn+z+Enihpks3xGqOmRt7S/ZKk2i8+U8tuvRQ+MksnPvyzXKFhckVE+lVvrui28h5h9Boaxj8TW3zHeP36xgep2hqRZfgnb4I2WnLLli3Kzc09KbFJksvlUm5urm+UzOnk5+ervLzcb8k/41nwCXFJoWGq+eIzWTXVannRJf+3KylZLeISVPMZz9tgv38mto5dO+rBmx5WxZGjwQ7JWZrQaMmGELTKLSEhQRs3blSvXr3q3L9x40bFx8ef8TqBzq9wsvCb71TNxxvk/fqQ1KqVwn6Urpa9+6tyyq+lY1U68cH/qFX2L2VVVsj6/pgi7rhPNTu2MZgEZyU8IlwduyT51hOTE9St9/k6euSovjn0rSa++Ki69+2uR8Y+ppAWIWob11aSdPTIUdVU1wQrbBgiaMntgQce0F133aWSkhINHTrUl8jKysq0evVqvfTSS/rv//7vYIVnpJDoGEXc+xuFtI2VdaxKtV99ocopv/aNkDw2t1CtvF61fuBxuVqGqnrLJh17eXpwg0az1TPlAj3z5tO+9Xsm/vDZkhVvvq/5z76my4b98C7B378/y++8X13/a21Z/0njBepUhn+sNKiv31q0aJGmTZumkpIS1dbWSpJatGih1NRU5eXl6YYbbji7C/P6LTQwXr+FxtJQr9+qevwW267V+rHXbbuWXYI6FeDGG2/UjTfeqOrqan399deSpPbt2ys0NDSYYQEAmrkmMYk7NDQ04FerAADOgeGjJZtEcgMANLImOsrRLrw4GQBgHCo3AHAiw0dLktwAwIloSwIA0LxQuQGAA5n+bkmSGwA4EW1JAACaFyo3AHAiwys3khsAOJHhUwFoSwIAjEPlBgBORFsSAGAay/DkRlsSAGAcKjcAcCLDKzeSGwA4keFvKKEtCQAwDpUbADgRbUkAgHEMT260JQEAxqFyAwAHsiyzKzeSGwA4EW1JAACaFyo3AHAiwys3khsAOBDvlgQAoJmhcgMAJzK8ciO5AYATmf1qSdqSAADzULkBgAOZPqCE5AYATmR4cqMtCQBoNLNmzVJKSoqioqIUFRWltLQ0vfvuu779x48fV05Ojtq1a6fIyEhlZWWprKws4PuQ3ADAibw2LgHo1KmTpk6dqpKSEn300UcaMmSIMjMz9emnn0qScnNztWzZMr355psqLi7WgQMHNGbMmIB/Hm1JAHCgYD1zGzVqlN/6lClTNGvWLK1fv16dOnXS7NmztWDBAg0ZMkSSNGfOHF144YVav369Bg0aVO/7ULkBAM6Jx+NRRUWF3+LxeM54Xm1trRYuXKiqqiqlpaWppKRE1dXVSk9P9x3Tq1cvde7cWevWrQsoJpIbADiRjW3JgoICRUdH+y0FBQWnvPXWrVsVGRkpt9utu+++W0uWLFHv3r1VWlqqsLAwxcTE+B0fHx+v0tLSgH4ebUkAcCA725L5+fnKy8vz2+Z2u095fM+ePbV582aVl5dr8eLFys7OVnFxsW3xSCQ3AMA5crvdp01m/y4sLEzdu3eXJKWmpmrTpk167rnndOONN+rEiRM6cuSIX/VWVlamhISEgGKiLQkAThSk0ZJ1huL1yuPxKDU1VaGhoVq9erVv344dO7Rnzx6lpaUFdE0qNwBwICtI75bMz89XRkaGOnfurKNHj2rBggUqKirSihUrFB0drXHjxikvL0+xsbGKiorS+PHjlZaWFtBISYnkBgBoRIcOHdJtt92mgwcPKjo6WikpKVqxYoWuvvpqSdK0adMUEhKirKwseTweDR8+XDNnzgz4PiQ3AHCiIFVus2fPPu3+8PBwFRYWqrCw8JzuQ3IDAAcKVluysTCgBABgHCo3AHAiwys3khsAOBBtSQAAmhkqNwBwINMrN5IbADiQ6cmNtiQAwDhUbgDgRJYr2BE0KJIbADgQbUkAAJoZKjcAcCDLS1sSAGAY2pIAADQzVG4A4EAWoyUBAKahLQkAQDND5QYADmT6aEkqNwCAcajcAMCBLCvYETQskhsAOBBtSQAAmhkqNwBwINMrN5IbADiQ6c/caEsCAIxD5QYADkRbEgBgHNPfLXlObcnjx4/bFQcAALYJOLl5vV799re/VceOHRUZGakvvvhCkvToo49q9uzZtgcIALCf5bVvaYoCTm5PPPGE5s6dq6eeekphYWG+7X379tXLL79sa3AAgIbhtVy2LU1RwMlt/vz5+v3vf69bbrlFLVq08G3v16+ftm/fbmtwAACcjYAHlOzfv1/du3c/abvX61V1dbUtQQEAGhYDSv5N7969tXbt2pO2L168WBdffLEtQQEAGpblddm2NEUBV26PPfaYsrOztX//fnm9Xr311lvasWOH5s+fr+XLlzdEjAAABCTgyi0zM1PLli3TqlWr1Lp1az322GP6+9//rmXLlunqq69uiBgBADazLPuWpuisJnFfccUVWrlypd2xAAAaSVNtJ9qFd0sCAIwTcOUWEhIil+vUGb+2tvacAgIANLymOj/NLgEntyVLlvitV1dX6+OPP9a8efM0efJk2wIDADScYE0FKCgo0FtvvaXt27erVatWuuyyy/Tkk0+qZ8+evmOuvPJKFRcX+533i1/8Qi+88EK97xNwcsvMzDxp23XXXac+ffpo0aJFGjduXKCXBAA4RHFxsXJycjRgwADV1NToN7/5jYYNG6a//e1vat26te+4O++8U48//rhvPSIiIqD72PZVgEGDBumuu+6y63IAgAYUrFGO7733nt/63Llz1aFDB5WUlGjw4MG+7REREUpISDjr+9gyoOT777/XjBkz1LFjRzsuBwBoYHa+W9Lj8aiiosJv8Xg89YqjvLxckhQbG+u3/fXXX1f79u3Vt29f5efn69ixYwH9voArt7Zt2/oNKLEsS0ePHlVERIRee+21QC8HAGjmCgoKThpzMXHiRE2aNOm053m9Xk2YMEGXX365+vbt69t+880367zzzlNSUpI++eQTPfTQQ9qxY4feeuutescUcHKbPn2633pISIji4uI0cOBAtW3bNtDLAQCCwM4BJfn5+crLy/Pb5na7z3heTk6Otm3bpr/85S9+2//1EddFF12kxMREDR06VLt27VK3bt3qFVNAya2mpkZfffWV7rjjDnXq1CmQUwEATYidz9zcbne9ktm/uvfee7V8+XKtWbPmjPlk4MCBkqSdO3c2THJr2bKlnn76ad12222BnBY0bRcXn/kgwAar9r0f7BCAZsGyLI0fP15LlixRUVGRunbtesZzNm/eLElKTEys930CbksOGTJExcXF6tKlS6CnAgCaiGBN4s7JydGCBQv09ttvq02bNiotLZUkRUdHq1WrVtq1a5cWLFigkSNHql27dvrkk0+Um5urwYMHKyUlpd73CTi5ZWRk6OGHH9bWrVuVmprqNy9Bkq655ppALwkAaGTBmsQ9a9YsST9M1P5Xc+bM0dixYxUWFqZVq1Zp+vTpqqqqUnJysrKysvTII48EdB+XZQXWeQ0JOfXsAZfL1TRev3Wa14MBQLNk88S0TR2vte1aA/YvOfNBjSzgys3r9TZEHA2iZWhSsEOAoWqqD/itVx/eFaRIYLrQuPoNoAiU6e+WDHgS9/z58+ucnHfixAnNnz/flqAAAA3LsnFpigJObrfffrtvRvm/Onr0qG6//XZbggIA4FwE3Ja0LKvOT97s27dP0dHRtgQFAGhYprcl653cLr74YrlcLrlcLg0dOlQtW/7fqbW1tdq9e7dGjBjRIEECAOwVrNGSjaXeyW306NGSfphMN3z4cEVGRvr2hYWFqUuXLsrKyrI9QAAAAlXv5DZx4kRJUpcuXXTjjTcqPDz8tMe/8cYbuuaaa06aBwcACL7mM+797AQ8oCQ7O/uMiU364aupZWVlZxUUAKBhWXLZtjRFtnzPrS4Bzg0HAMA2tn2JGwDQfHgNrz9IbgDgQN4m2k60S4O1JQEACBYqNwBwoKY6EMQuZzVacs2aNWc87rzzzlNoaOhZBQUAaFheG5emKODkVl5ervT0dPXo0UP/9V//pf3799d53LZt25ScnHzOAQIAEKiAk9vSpUu1f/9+3XPPPVq0aJG6dOmijIwMLV68WNXV1Q0RIwDAZsxzq0NcXJzy8vK0ZcsWbdiwQd27d9ett96qpKQk5ebm6vPPP7c7TgCAjWhLnsbBgwe1cuVKrVy5Ui1atNDIkSO1detW9e7dW9OmTbMrRgAAAhLwaMnq6mq98847mjNnjt5//32lpKRowoQJuvnmmxUVFSVJWrJkie644w7l5ubaHjAA4Nw11YrLLgEnt8TERHm9Xt10003auHGj+vfvf9IxV111lWJiYmwIDwDQEJrqszK7BJzcpk2bpuuvv/60L0+OiYnR7t27zykwAADOVsDJ7dZbb22IOAAAjchrduHGG0oAwIl4tyQAAM0MlRsAOJDhX7whuQGAE5k+FYC2JADAOFRuAOBAXpfZA0pIbgDgQKY/c6MtCQAwDpUbADiQ6QNKSG4A4ECmv6GEtiQAwDhUbgDgQKa/fovkBgAOxGhJAACaGSo3AHAg0weUkNwAwIFMnwpAWxIA0GgKCgo0YMAAtWnTRh06dNDo0aO1Y8cOv2OOHz+unJwctWvXTpGRkcrKylJZWVlA9yG5AYADWTYugSguLlZOTo7Wr1+vlStXqrq6WsOGDVNVVZXvmNzcXC1btkxvvvmmiouLdeDAAY0ZMyag+7gsyzJv0Mw/XgjaMjQpyIHAVDXVB/zWqw/vClIkMF1oXLcf/mDzX9WzO/3MtmuN2/faWZ97+PBhdejQQcXFxRo8eLDKy8sVFxenBQsW6LrrrpMkbd++XRdeeKHWrVunQYMG1eu6VG4AgKApLy+XJMXGxkqSSkpKVF1drfT0dN8xvXr1UufOnbVu3bp6X5cBJQDgQHYOKPF4PPJ4PH7b3G633G736WPwejVhwgRdfvnl6tu3rySptLRUYWFhiomJ8Ts2Pj5epaWl9Y6Jyg0AHMhr41JQUKDo6Gi/paCg4Iwx5OTkaNu2bVq4cKHdP4/KDQBwbvLz85WXl+e37UxV27333qvly5drzZo16tSpk297QkKCTpw4oSNHjvhVb2VlZUpISKh3TFRuAOBAlsu+xe12Kyoqym85VXKzLEv33nuvlixZog8++EBdu3b125+amqrQ0FCtXr3at23Hjh3as2eP0tLS6v37qNwAwIGCNYk7JydHCxYs0Ntvv602bdr4nqNFR0erVatWio6O1rhx45SXl6fY2FhFRUVp/PjxSktLq/dISYnkBgBoRLNmzZIkXXnllX7b58yZo7Fjx0qSpk2bppCQEGVlZcnj8Wj48OGaOXNmQPdhnhtwFpjnhsbSUPPcnk+2b57bvXvPfp5bQ6FyAwAHMq+q8ceAEgCAcajcAMCB+OQNAMA4fPIGAIBmhsoNABzI9MqN5AYADsRoSQAAmhkqNwBwIEZLAgCMY/ozN9qSAADjULkBgAOZPqCE5AYADuQ1PL3RlgQAGIfKDQAcyPQBJSQ3AHAgs5uStCUBAAaicgMAB6ItCQAwjulvKKEtCQAwDpUbADiQ6fPcSG4A4EBmpzbakgAAA1G5AYADMVoSAGAc05+50ZYEABiHyg0AHMjsuo3kBgCOZPozN9qSAADjULkBgAOZPqCE5AYADmR2aqMtCQAwEJUbADiQ6QNKSG4A4ECW4Y1J2pIAAONQuQGAA9GWBAAYx/SpALQlAQDGoXIDAAcyu26jcgMAR/LKsm0JxJo1azRq1CglJSXJ5XJp6dKlfvvHjh0rl8vlt4wYMSLg30dyc7DHHs1TzYn9fsu2rcXBDgsGevnVP6jv5RmaOv2Fk/ZZlqW7f/Wo+l6eodVrPgxCdGhMVVVV6tevnwoLC095zIgRI3Tw4EHf8sYbbwR8H9qSDrft0+0aPuKnvvWampogRgMTbf37Dr359v/ogu5d69z/6qKlcjVyTAjeaMmMjAxlZGSc9hi3262EhIRzug+Vm8PV1NSqrOywb/nmm++CHRIMcuzY93p48tOa9ND9imoTedL+7Z/t0ryFf9Rvf5MbhOiczbLxP4/Ho4qKCr/F4/GcdWxFRUXq0KGDevbsqXvuuUfffPNNwNcguTlcj+5dtefLEn22/UPNn/c7JScnBTskGOSJZwo1OG2A0gZcfNK+748f14OTn9R//ipH7dvFBiE62KWgoEDR0dF+S0FBwVlda8SIEZo/f75Wr16tJ598UsXFxcrIyFBtbW1A12nSbcm9e/dq4sSJeuWVV055jMfjOelfCO5/LDi9jRs/1h0/z9Vnn+1SYkIHPfpInoo+WKJ+Fw9RZWVVsMNDM/c/q4r09892aeHLz9W5/6kZv1f/vr015Iq0Ro4Mkr1tyfz8fOXl5fltc7vP7m/hn/70/x6TXHTRRUpJSVG3bt1UVFSkoUOH1vs6Tbpy+/bbbzVv3rzTHlPnvxgaKb7m7r0Vf9Yf/7hcW7f+Xe+vLNb/u+ZWxcRE6frrRgU7NDRzB8sOa+r0FzV14oNyu8NO2v/nteu1oWSLHr7/F0GIDpK9bUm3262oqCi/5WyT2787//zz1b59e+3cuTOg84Jaub3zzjun3f/FF1+c8Rp1/oshOvqc4nKq8vIKffb5F+revUuwQ0Ez97cdn+vb747ohjvu9W2rrfWqZPM2vfHWMt04+ifau/+g0kZc53de7n9O0SX9+mju8081dshoovbt26dvvvlGiYmJAZ0X1OQ2evRouVwuWdap50m4XKcfR+V2u237F4LTtW4doW7nn6fXX/9jsENBMzcotb+WvDrLb9sjU55V1/OSNe5n16ttdJSuHz3Sb/+1t96jB++7S1dePrAxQ3WsYI2WrKys9KvCdu/erc2bNys2NlaxsbGaPHmysrKylJCQoF27dunBBx9U9+7dNXz48IDuE9TklpiYqJkzZyozM7PO/Zs3b1ZqamojR+UcT019VMv/tFJf7dmnpMQETXzsV6qt9WrhoqXBDg3NXOvWEepxfhe/ba1ahSsmqo1ve12DSBLj49Qp6dyGgKN+vKcpKhrSRx99pKuuusq3/s/OW3Z2tmbNmqVPPvlE8+bN05EjR5SUlKRhw4bpt7/9bcBFTFCTW2pqqkpKSk6Z3M5U1eHcdOyUqNdeLVS7dm11+PC3+t8PN+ryK0bp66+/DXZoAAx15ZVXnvbv9RUrVthyH5cVxOyxdu1aVVVVnfLVKlVVVfroo4/04x//OLAL/6OV2TKUYe1oGDXVB/zWqw/vClIkMF1oXLcf/mDzX9U/O2+Mbdd67au3bLuWXYJauV1xxRWn3d+6devAExsA4Iz45A0AAM1Mk57EDQBoGJbhlRvJDQAcKFhTARoLbUkAgHGo3ADAgUwfUEJyAwAHMv2ZG21JAIBxqNwAwIFMH1BCcgMABzL91Ya0JQEAxqFyAwAHYrQkAMA4pj9zoy0JADAOlRsAOJDp89xIbgDgQKY/c6MtCQAwDpUbADiQ6fPcSG4A4ECMlgQAoJmhcgMAB2K0JADAOIyWBACgmaFyAwAHYrQkAMA4tCUBAGhmqNwAwIEYLQkAMI7X8GdutCUBAMahcgMABzK7biO5AYAjMVoSAIBmhsoNABzI9MqN5AYADmT6G0poSwIAjEPlBgAORFsSAGAc099QQlsSANBo1qxZo1GjRikpKUkul0tLly71229Zlh577DElJiaqVatWSk9P1+effx7wfUhuAOBAlmXZtgSiqqpK/fr1U2FhYZ37n3rqKc2YMUMvvPCCNmzYoNatW2v48OE6fvx4QPehLQkADhSsZ24ZGRnKyMioc59lWZo+fboeeeQRZWZmSpLmz5+v+Ph4LV26VD/96U/rfR8qNwDAOfF4PKqoqPBbPB5PwNfZvXu3SktLlZ6e7tsWHR2tgQMHat26dQFdi+QGAA5kZ1uyoKBA0dHRfktBQUHAMZWWlkqS4uPj/bbHx8f79tUXbUkAcCA725L5+fnKy8vz2+Z2u227/tkguQEAzonb7bYlmSUkJEiSysrKlJiY6NteVlam/v37B3Qt2pIA4ECWjf/ZpWvXrkpISNDq1at92yoqKrRhwwalpaUFdC0qNwBwoGB9ibuyslI7d+70re/evVubN29WbGysOnfurAkTJuiJJ55Qjx491LVrVz366KNKSkrS6NGjA7oPyQ0A0Gg++ugjXXXVVb71fz6ry87O1ty5c/Xggw+qqqpKd911l44cOaIf/ehHeu+99xQeHh7QfVyWia+GdrkkSS1Dk4IcCExVU33Ab7368K4gRQLThcZ1++EPNv9V3Sd+oG3X+rRsg23XsguVGwA4ULDako2FASUAAONQuQGAA5n+VQCSGwA4EG1JAACaGSo3AHAg2pIAAOPQlgQAoJmhcgMAB6ItCQAwjmV5gx1Cg6ItCQAwDpUbADiQnR8rbYqo3AAAxqFyAwAHMvGDMP+K5AYADkRbEgCAZobKDQAciLYkAMA4vH4LAIBmhsoNAByI128BAIxj+jM32pIAAONQuQGAA5k+z43kBgAORFsSAIBmhsoNABzI9HluJDcAcCDakgAANDNUbgDgQIyWBAAYh7YkAADNDJUbADgQoyUBAMYx/cXJtCUBAMahcgMAB6ItCQAwDqMlAQBoZqjcAMCBTB9QQnIDAAeiLQkAgE0mTZokl8vlt/Tq1cv2+1C5AYADBbNy69Onj1atWuVbb9nS/lRkdHKrqT4Q7BDgEKFx3YIdAhCQYDYlW7ZsqYSEhAa9B21JAMA58Xg8qqio8Fs8Hs8pj//888+VlJSk888/X7fccov27Nlje0wuy/SniqgXj8ejgoIC5efny+12BzscGIz/18wzadIkTZ482W/bxIkTNWnSpJOOfffdd1VZWamePXvq4MGDmjx5svbv369t27apTZs2tsVEcoMkqaKiQtHR0SovL1dUVFSww4HB+H/NPB6P56RKze121+sfL0eOHNF5552nZ599VuPGjbMtJqOfuQEAGl59E1ldYmJidMEFF2jnzp22xsQzNwBA0FRWVmrXrl1KTEy09bokNwBAo3nggQdUXFysL7/8Uh9++KGuvfZatWjRQjfddJOt96EtCUk/tBUmTpzIA340OP5fc7Z9+/bppptu0jfffKO4uDj96Ec/0vr16xUXF2frfRhQAgAwDm1JAIBxSG4AAOOQ3AAAxiG5AQCMQ3KDCgsL1aVLF4WHh2vgwIHauHFjsEOCgdasWaNRo0YpKSlJLpdLS5cuDXZIMBjJzeEWLVqkvLw8TZw4UX/961/Vr18/DR8+XIcOHQp2aDBMVVWV+vXrp8LCwmCHAgdgKoDDDRw4UAMGDNDzzz8vSfJ6vUpOTtb48eP18MMPBzk6mMrlcmnJkiUaPXp0sEOBoajcHOzEiRMqKSlRenq6b1tISIjS09O1bt26IEYGAOeG5OZgX3/9tWpraxUfH++3PT4+XqWlpUGKCgDOHckNAGAckpuDtW/fXi1atFBZWZnf9rKysgb/BDwANCSSm4OFhYUpNTVVq1ev9m3zer1avXq10tLSghgZAJwbvgrgcHl5ecrOztall16q//iP/9D06dNVVVWl22+/PdihwTCVlZV+H6TcvXu3Nm/erNjYWHXu3DmIkcFETAWAnn/+eT399NMqLS1V//79NWPGDA0cODDYYcEwRUVFuuqqq07anp2drblz5zZ+QDAayQ0AYByeuQEAjENyAwAYh+QGADAOyQ0AYBySGwDAOCQ3AIBxSG4AAOOQ3IAmZOzYsXzjDLAByQ0AYBySG2CzEydOBDsEwPFIbjDe/Pnz1a5dO3k8Hr/to0eP1q233nracydNmqT+/fvrxRdfVHJysiIiInTDDTeovLzcd8w/W4lTpkxRUlKSevbsKUnau3evbrjhBsXExCg2NlaZmZn68ssvfefV1tYqLy9PMTExateunR588EHxNjzAHiQ3GO/6669XbW2t3nnnHd+2Q4cO6U9/+pPuuOOOM56/c+dO/eEPf9CyZcv03nvv6eOPP9Yvf/lLv2NWr16tHTt2aOXKlVq+fLmqq6s1fPhwtWnTRmvXrtX//u//KjIyUiNGjPBVds8884zmzp2rV155RX/5y1/07bffasmSJfb+eMCpLMAB7rnnHisjI8O3/swzz1jnn3++5fV6T3vexIkTrRYtWlj79u3zbXv33XetkJAQ6+DBg5ZlWVZ2drYVHx9veTwe3zGvvvqq1bNnT7/rezweq1WrVtaKFSssy7KsxMRE66mnnvLtr66utjp16mRlZmae028FYFl8zw2OcOedd2rAgAHav3+/OnbsqLlz52rs2LFyuVxnPLdz587q2LGjbz0tLU1er1c7duzwfbH8oosuUlhYmO+YLVu2aOfOnWrTpo3ftY4fP65du3apvLxcBw8e9Pu0UMuWLXXppZfSmgRsQHKDI1x88cXq16+f5s+fr2HDhunTTz/Vn/70J9uu37p1a7/1yspKpaam6vXXXz/p2Li4ONvuC6BuJDc4xs9//nNNnz5d+/fvV3p6upKTk+t13p49e3TgwAElJSVJktavX6+QkBDfwJG6XHLJJVq0aJE6dOigqKioOo9JTEzUhg0bNHjwYElSTU2NSkpKdMkllwT4ywD8OwaUwDFuvvlm7du3Ty+99FK9BpL8U3h4uLKzs7VlyxatXbtW9913n2644QZfS7Iut9xyi9q3b6/MzEytXbtWu3fvVlFRke677z7t27dPknT//fdr6tSpWrp0qbZv365f/vKXOnLkyLn+TAAiucFBoqOjlZWVpcjIyIDeAtK9e3eNGTNGI0eO1LBhw5SSkqKZM2ee9pyIiAitWbNGnTt31pgxY3ThhRdq3LhxOn78uK+S+9WvfqVbb71V2dnZSktLU5s2bXTttdeey08E8A8ui6fXcJChQ4eqT58+mjFjRr2OnzRpkpYuXarNmzc3bGAAbMUzNzjCd999p6KiIhUVFZ2x6gLQ/JHc4AgXX3yxvvvuOz355JN+A0H69Omjr776qs5zXnzxxcYKD4DNaEvC0b766itVV1fXuS8+Pv6keWoAmgeSGwDAOIyWBAAYh+QGADAOyQ0AYBySGwDAOCQ3AIBxSG4AAOOQ3AAAxiG5AQCM8/8BpiSYOAu4/kgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.71      0.78        42\n",
            "           1       0.79      0.90      0.84        49\n",
            "\n",
            "    accuracy                           0.81        91\n",
            "   macro avg       0.82      0.81      0.81        91\n",
            "weighted avg       0.82      0.81      0.81        91\n",
            "\n",
            "\n",
            "The classification report summarizes key metrics such as precision, \n",
            "recall, F1-score, and support for each class in a classification problem, \n",
            "providing insights into the model's performance and helping to assess \n",
            "its effectiveness in correctly classifying instances.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}